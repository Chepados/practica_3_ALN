{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<center><img src=\"media/imagenes/Banner.png\" height = 100 width = 1000></center>",
   "id": "d962182cfdf723d6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T10:29:43.055274Z",
     "start_time": "2025-01-14T10:29:42.750563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sys import implementation\n",
    "\n",
    "import dependencias\n",
    "from pprint import pprint"
   ],
   "id": "111b71fb835de854",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.1)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Reglas\n",
    "\n",
    "Hay que enseñar lo que hemos implentado del juego base"
   ],
   "id": "22f54753c31fe610"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Agentes",
   "id": "bc289102eebca739"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Agentes Basados en Heuristicas.\n",
    "\n",
    "Hemos definido un primer tipo de agente basado en heurísticas que se basa en los siguientes pasos:\n",
    "\n",
    "- get_reward: Calcula la recompensa para cada movimiento en funcion de una politica de recompensa.\n",
    "- get_action: Calcula la mejor acción a realizar en función de la recompensa obtenida.\n",
    "\n",
    "de este modo podemos empezar a jugar con el agente y ver como se comporta."
   ],
   "id": "4ebbbd6af6c0c68d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Agentes Chaser\n",
    "\n",
    "La politica de recompensa de este agente se basa en la distancia entre la cabeza de la serpiente y la comida, de este modo el agente siempre intentará acercarse a la comida, aunque esto implique que la serpiente se muera."
   ],
   "id": "3e9d7108e737e3f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T00:13:45.820784Z",
     "start_time": "2025-01-14T00:13:45.817770Z"
    }
   },
   "cell_type": "code",
   "source": "agente_chaser = dependencias.Agentes.ChaserAgent()",
   "id": "ce71e919a9774741",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T23:08:54.374752Z",
     "start_time": "2025-01-13T23:08:52.179042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ejecuta esta celda para ver como se comporta el agente\n",
    "game = dependencias.Snake_game((15, 15), 5, agente_chaser)\n",
    "game.play_with_pygame()"
   ],
   "id": "8b93e851f276b71d",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T23:12:09.371202Z",
     "start_time": "2025-01-13T23:12:09.309544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "estadisticas = game.evaluar()\n",
    "pprint(estadisticas)"
   ],
   "id": "a40361a9bfbb8600",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 1775.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movimientos por puntuacion': np.float64(4.296235679214402),\n",
      " 'movimientos_maximos': np.int64(115),\n",
      " 'movimientos_medios': np.float64(26.25),\n",
      " 'movimientos_minimos': np.int64(5),\n",
      " 'puntuacion_maxima': np.int64(23),\n",
      " 'puntuacion_media': np.float64(6.11),\n",
      " 'puntuacion_minima': np.int64(3)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Conclusiones\n",
    "\n",
    "Este agente tarda solo 4 movimientos en conseguir la comida, pero no alcanza puntuaciones muy altas.\n",
    "\n",
    "### Mejoras\n",
    "\n",
    "Este agente podría ser mejorado si se le añade una penalización por muerte inmediata."
   ],
   "id": "982affadbdb6076b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "11254478ce44f5cc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Agentes Avoider\n",
    "\n",
    "La politica de recompensa de este agente se basa en evitar las muertes inediatas, ya sea contra la serpriente o contra las paredes, asociando una penalización a estos movimientos."
   ],
   "id": "5895a96839b301c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T00:13:48.638862Z",
     "start_time": "2025-01-14T00:13:48.635482Z"
    }
   },
   "cell_type": "code",
   "source": "agente_avoider = dependencias.Agentes.Avoid_inmediate_death()",
   "id": "47d1db2bdeefc94d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T23:15:34.687827Z",
     "start_time": "2025-01-13T23:14:45.679318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ejecuta esta celda para ver como se comporta el agente\n",
    "game = dependencias.Snake_game((15, 15), 5, agente_avoider)\n",
    "game.play_with_pygame()"
   ],
   "id": "34242dee54cd21fe",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T23:15:44.868171Z",
     "start_time": "2025-01-13T23:15:44.625383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "estadisticas = game.evaluar()\n",
    "pprint(estadisticas)"
   ],
   "id": "3161d72e0bd1f13b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 421.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movimientos por puntuacion': np.float64(59.01053740779768),\n",
      " 'movimientos_maximos': np.int64(1268),\n",
      " 'movimientos_medios': np.float64(560.01),\n",
      " 'movimientos_minimos': np.int64(91),\n",
      " 'puntuacion_maxima': np.int64(17),\n",
      " 'puntuacion_media': np.float64(9.49),\n",
      " 'puntuacion_minima': np.int64(4)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Conclusiones\n",
    "\n",
    "Este agente majora mucho su tiempo de vida, pero no consigue alcanzar la comida de manera eficiente.\n",
    "\n",
    "### Mejoras\n",
    "\n",
    "Ademas vemos que con evitar muertes inmediatas no es suficiente, puesto que hay escenarios en los que te puedes quedar encerrado."
   ],
   "id": "4ce8684424ccb852"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Combinacion de agentes\n",
    "\n",
    "Esta implementation de los agentes tan particular, nos perite combinar las recompensas que le dan a cada movimiento distintos agentes para conseguir un agente que se comporte de una manera más eficiente."
   ],
   "id": "b27f538b5d98c989"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T00:10:10.073119Z",
     "start_time": "2025-01-14T00:10:09.832960Z"
    }
   },
   "cell_type": "code",
   "source": "agente_combinado = dependencias.Agentes.Combined_agent((agente_avoider, agente_chaser), (1, 0.5))",
   "id": "26314a8eefae079a",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agente_chaser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m agente_combinado \u001B[38;5;241m=\u001B[39m dependencias\u001B[38;5;241m.\u001B[39mAgentes\u001B[38;5;241m.\u001B[39mCombined_agent((agente_avoider, \u001B[43magente_chaser\u001B[49m), (\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0.5\u001B[39m))\n",
      "\u001B[1;31mNameError\u001B[0m: name 'agente_chaser' is not defined"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T10:34:00.357665Z",
     "start_time": "2025-01-14T10:33:24.789689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ejecuta esta celda para ver como se comporta el agente\n",
    "game = dependencias.Snake_game((15, 15), 5, agente_combinado)\n",
    "game.play_with_pygame()"
   ],
   "id": "fed9b2ad778e7e8f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T23:24:16.325384Z",
     "start_time": "2025-01-13T23:24:16.090221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "estadisticas = game.evaluar()\n",
    "pprint(estadisticas)"
   ],
   "id": "d6df7ca7bbbc7ec1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 440.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movimientos por puntuacion': np.float64(60.81171067738231),\n",
      " 'movimientos_maximos': np.int64(2610),\n",
      " 'movimientos_medios': np.float64(529.67),\n",
      " 'movimientos_minimos': np.int64(133),\n",
      " 'puntuacion_maxima': np.int64(16),\n",
      " 'puntuacion_media': np.float64(8.71),\n",
      " 'puntuacion_minima': np.int64(4)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Conclusiones\n",
    "\n",
    "El comportaiento de este agente es mucho mejor que el de los agentes individuales, y parece una buena estrategia para el inicio del juego.\n",
    "\n",
    "### Mejoras\n",
    "\n",
    "El agente sigue sin ser capaz de evitar quedarse encerrado, hay que añadir una heuristica mas a futuro para evitar este tipo de situaciones."
   ],
   "id": "b6b8c6818edb8ffc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T10:44:16.097935Z",
     "start_time": "2025-01-14T10:43:45.154487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "agente_searcher = dependencias.Agentes.Aantiloop()\n",
    "agente_avoider = dependencias.Agentes.Avoid_inmediate_death()\n",
    "agente_chaser = dependencias.Agentes.ChaserAgent()\n",
    "\n",
    "agente_combinado = dependencias.Agentes.Combined_agent((agente_avoider, agente_chaser, agente_searcher), (1, 0, 10))\n",
    "game = dependencias.Snake_game((15, 15), 5, agente_combinado)\n",
    "game.play_with_pygame()"
   ],
   "id": "bff528cebd91a5c6",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T10:45:05.197097Z",
     "start_time": "2025-01-14T10:44:31.114411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "estadisticas = game.evaluar(10)\n",
    "pprint(estadisticas)"
   ],
   "id": "2e61d47864b2b6f2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:34<00:00,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movimientos por puntuacion': np.float64(40.07934508816121),\n",
      " 'movimientos_maximos': np.int64(3628),\n",
      " 'movimientos_medios': np.float64(3182.3),\n",
      " 'movimientos_minimos': np.int64(2509),\n",
      " 'puntuacion_maxima': np.int64(98),\n",
      " 'puntuacion_media': np.float64(79.4),\n",
      " 'puntuacion_minima': np.int64(66)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T10:46:29.782256Z",
     "start_time": "2025-01-14T10:46:27.714319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "agente_combinado = dependencias.Agentes.Combined_agent((agente_avoider, agente_chaser, agente_searcher), (1, 0.2, 3))\n",
    "game = dependencias.Snake_game((15, 15), 5, agente_combinado)\n",
    "game.play_with_pygame()"
   ],
   "id": "8da367cd76aab33f",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T10:50:07.886054Z",
     "start_time": "2025-01-14T10:49:10.498605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "estadisticas = game.evaluar(100)\n",
    "pprint(estadisticas)"
   ],
   "id": "4f167c2222d2eee0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:57<00:00,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movimientos por puntuacion': np.float64(6.8849013073570875),\n",
      " 'movimientos_maximos': np.int64(971),\n",
      " 'movimientos_medios': np.float64(537.16),\n",
      " 'movimientos_minimos': np.int64(294),\n",
      " 'puntuacion_maxima': np.int64(126),\n",
      " 'puntuacion_media': np.float64(78.02),\n",
      " 'puntuacion_minima': np.int64(48)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "413c962dc7316050"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
